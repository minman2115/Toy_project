{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  트위터 스트리밍 데이터 실시간 감성분석 시스템 구현결과\n",
    "\n",
    "> 카프카를 이용한 트위터 스트리밍 데이터 처리 및 감성분석, 시각화 파이프라인 구축\n",
    "\n",
    "### 1. 개요\n",
    "\n",
    "#### 1.1. 아이디어\n",
    "\n",
    "- 트위터 스트리밍 데이터를 실시간으로 처리하는 카프카 시스템 구축 아이디어 구상\n",
    "\n",
    "\n",
    "- 데이터를 처리하는 방식은 기존에 감성분석 training이 되어있는 딥러닝 모델을 차용하여 트위터 스트리밍 데이터에 적용\n",
    "\n",
    "\n",
    "- Dash를 이용하여 스트리밍 데이터 처리결과에 대한 시각화 구현\n",
    "\n",
    "\n",
    "#### 1.2.  프로젝트 구현 아키텍처"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"1.png\" width=\"1000\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. 기술스텍\n",
    "\n",
    "0) 시스템 구현 환경 : 우분투 리눅스, 파이썬 3.7\n",
    "\n",
    "1) 트위터 스트리밍 데이터 API와 Kafka 연결 : Kafka Connect Twitter packages\n",
    "\n",
    "- URL : https://github.com/Eneco/kafka-connect-twitter\n",
    "\n",
    "2) 트위터 스트리밍 데이터 처리 및 모니터링 : Kafka\n",
    "\n",
    "\n",
    "- 버전 : 2.2.0\n",
    "\n",
    "\n",
    "3) Kafka로 부터 트위터 스트리밍 데이터를 받아서 Batch 단위로 모델링 적용 및 처리 : Spark streaming\n",
    "\n",
    "\n",
    "- 버전 : 2.4.0\n",
    "\n",
    "\n",
    "4) 감성분석 모델 적용 : DeepMoji\n",
    "\n",
    "- 예측하는 감성에 맞는 이모티콘을 Return 하는 딥러닝 모델\n",
    "\n",
    "\n",
    "- URL : https://github.com/bfelbo/DeepMoji\n",
    "\n",
    "\n",
    "- 버전 : 0.4.5\n",
    "\n",
    "5) 모델링 적용 결과 시각화 : Dash\n",
    "\n",
    "\n",
    "6) 기타 필요한 패키지\n",
    "\n",
    "- keras 2.0.9\n",
    "\n",
    "\n",
    "- h5py\n",
    "\n",
    "\n",
    "- numpy\n",
    "\n",
    "\n",
    "- scikit-learn\n",
    "\n",
    "\n",
    "- tensorflow 1.13.1\n",
    "\n",
    "\n",
    "- text-unidecode 1.0\n",
    "\n",
    "\n",
    "### 2. 시스템 구동방법\n",
    "\n",
    "step 1) kafka server 구동\n",
    "\n",
    "step 2) kafka connect twitter package 실행\n",
    "\n",
    "- twitter streaming data API에서 kafka 연결\n",
    "\n",
    "\n",
    "- step 2)까지 수행결과 트위터 스트리밍 데이터가 카프카 콘솔로 실시간 전시되는 것을 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"2.png\" width=\"700\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 3) opear_dash.py를 실행하여 Dash 서버 구동\n",
    "\n",
    "\n",
    "step 4) Deepmoji 패키지 다운 및 setup.py 실행\n",
    "\n",
    "\n",
    "- setup.py 실행 전 아래와 같은 내용으로 수정필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"3.png\" width=\"700\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- setup.py 실행 시 명령어 : python setup.py install\n",
    "\n",
    "step 4) apply_model.py를 실행\n",
    "\n",
    "- 감성분석 모델 적용 및 데이터 처리, Dash로 전송\n",
    "\n",
    "\n",
    "- 실행 시 명령어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "./spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.0 apply_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 시스템 구동결과\n",
    "\n",
    "1) ./spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.0 apply_model.py 실행한 터미널"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"4.png\" width=\"1000\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5초마다 위와같은 데이터프레임 형식의 batch 업데이트 수행\n",
    "\n",
    "2) 웹브라우저로 접속한 Dash 로컬 서버"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"5.png\" width=\"1000\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5초마다 위와같은 데이터프레임 형식의 batch 업데이트 되면서 동시에 위와 같은 대시보드도 실시간으로 변동된다.\n",
    "\n",
    "3) opear_dash.py 실행 콘솔"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"6.png\" width=\"1000\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4. 프로젝트 로드맵 및 수행경과\n",
    "\n",
    "#### STEP 1) 문제정의 및 프로젝트 계획 구상\n",
    "\n",
    "- 아이디어 도출 \n",
    "\n",
    "\n",
    "- 프로젝트 구현 아키텍처 구상\n",
    "\n",
    "\n",
    "- 프로젝트 시행 계획 수립 -> 아키텍처 부분별 단계적인 구현\n",
    "\n",
    "\n",
    "#### STEP 2) Kafka를 이용한 데이터 스트리밍 데이터 수집\n",
    "\n",
    "\n",
    "- Kafka Connect Twitter package를 이용한 트위터 스트리밍 데이터 API와 Kafka 연결\n",
    "\n",
    "\n",
    "#### STEP 3) 트위터 스트리밍 데이터 실시간 대시보드 구현\n",
    "\n",
    "\n",
    "- 트위터 스트밍 데이터 중 헤시테그로 시작하는 문장을 word counting하여 Dash로 시각화 구현\n",
    "\n",
    "-> step 4)에서 '헤시테그로 시작하는 문장을 word counting'하는 부분을 emoji model을 적용하는 것으로 응용\n",
    "\n",
    "- step 3) 구현결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"7.png\" width=\"1000\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 4) emoji 모델을 적용한 스트리밍 데이터 처리 실시간 대시보드 구현\n",
    "\n",
    "- step 4) 구현 간 주요이슈 \n",
    "\n",
    "1) emoji 모델 구현환경이 python 버전 2 베이스로 3.7에서는 적용불가\n",
    "\n",
    "-> emoji 패키지에서 python 버전 2 부분을 3 버전으로 적용할 수 있도록 일부 파일 수정\n",
    "\n",
    "트러블 슈팅 시 참고한 URL : https://github.com/zzsza/DeepMoji-Python3\n",
    "\n",
    "2) 미니멀한 데이터프레임에 Deepmoji 적용 시 프로그램 구동효율 최적화 문제\n",
    "\n",
    "-> apply_model.py에서 st, model을 class화 하여 모델이 호출될때 broadcasting 할 수 있도록 구현"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
